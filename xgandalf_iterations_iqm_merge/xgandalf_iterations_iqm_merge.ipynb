{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the CrystFEL-based processing\n",
    "\n",
    "This notebook comprises a workflow using CrystFEL-based tools combined with original scripts. Below is a step-by-step guide:\n",
    "\n",
    "1. **Run Indexamajig** (`gandalf_iterator`)  \n",
    "   - Perform peakfinding, indexing, and integration for each HDF5 file in the specified folder, varying beam center coordinates on a grid withing a given radius.\n",
    "\n",
    "2. **Evaluate IQM** (`automate_evaluation`)  \n",
    "   - Parse stream files for indexing quality metrics (IQMs), apply weights, and identify the best results.\n",
    "\n",
    "3. **Merge** (`merge`)  \n",
    "   - Merge the best result stream file to refine cell parameters and symmetry.\n",
    "\n",
    "4. **Convert**  \n",
    "   - **to `.hkl`** for ShelX (`convert_hkl_crystfel_to_shelx`).  \n",
    "   - **to `.mtz`** for downstream crystallographic tools (`convert_hkl_to_mtz`).\n",
    "\n",
    "Please ensure that preprocessing (peak finding, center finding and center refinement) has been done and that you have the required packages and environment set up (CrystFEL, Python packages, etc.) before proceeding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Indexamajig with options for peakfinding, indexing and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gandalf_radial_iterator import gandalf_iterator\n",
    "\n",
    "geomfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTAsim.geom\"       # .geom file\n",
    "cellfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTA.cell\"          # .cell file\n",
    "\n",
    "input_path =   \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24\"      # .h5 folder will also be output folder\n",
    "\n",
    "output_file_base = \"LTA\"    # output files will be named output_file_base_xcoord_ycoord.h5\n",
    "\n",
    "num_threads = 8             # number of CPU threads to use\n",
    "x, y = 512.5, 512.5         # initial beam center from where iterations will start\n",
    "\n",
    "\"\"\"Define the grid and maximum radius for iterations.\n",
    "As example max_radius = 1, step = 0.2 will give 81 iterations.\n",
    "Iterations will start at the center and move radially outwards.\n",
    "\"\"\"\n",
    "max_radius = 1              # maximum radius in pixels\n",
    "step = 0.2                  # grid granularity in pixels\n",
    "\n",
    "extra_flags=[\n",
    "# PEAKFINDING\n",
    "\"--no-revalidate\",\n",
    "\"--no-half-pixel-shift\",\n",
    "\"--peaks=cxi\", \n",
    "\"--min-peaks=15\",\n",
    "# INDEXING\n",
    "\"--indexing=xgandalf\",\n",
    "\"--tolerance=10,10,10,5\",\n",
    "\"--no-refine\",\n",
    "\"--xgandalf-sampling-pitch=5\",\n",
    "\"--xgandalf-grad-desc-iterations=1\",\n",
    "\"--xgandalf-tolerance=0.02\",\n",
    "# INTEGRATION\n",
    "\"--integration=rings\",\n",
    "\"--int-radius=4,5,9\",\n",
    "\"--fix-profile-radius=70000000\",\n",
    "# OUTPUT\n",
    "\"--no-non-hits-in-stream\",\n",
    "]\n",
    "\n",
    "\"\"\"Examples of extra flags(see crystfel documentation https://www.desy.de/~twhite/crystfel/manual-indexamajig.html):\"\"\"\n",
    "\n",
    "\"\"\" Basic options\n",
    "\"--highres=n\",\n",
    "\"--no-image-data\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Peakfinding\n",
    "\"--peaks=cxi\",\n",
    "\"--peak-radius=inner,middle,outer\",\n",
    "\"--min-peaks=n\",\n",
    "\"--median-filter=n\",\n",
    "\"--filter-noise\",\n",
    "\"--no-revalidate\",\n",
    "\"--no-half-pixel-shift\",\n",
    "\n",
    "\"--peaks=peakfinder9\",\n",
    "\"--min-snr=1\",\n",
    "\"--min-snr-peak-pix=6\",\n",
    "\"--min-snr-biggest-pix=1\",\n",
    "\"--min-sig=9\",\n",
    "\"--min-peak-over-neighbour=5\",\n",
    "\"--local-bg-radius=5\",\n",
    "\n",
    "\"--peaks=peakfinder8\",\n",
    "\"--threshold=45\",\n",
    "\"--min-snr=3\",\n",
    "\"--min-pix-count=3\",\n",
    "\"--max-pix-count=500\",\n",
    "\"--local-bg-radius=9\",\n",
    "\"--min-res=30\",\n",
    "\"--max-res=500\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Indexing\n",
    "\"--indexing=xgandalf\",\n",
    "\n",
    "\"--tolerance=tol\"\n",
    "\"--no-check-cell\",\n",
    "\"--no-check-peaks\",\n",
    "\"--multi\",\n",
    "\"--no-retry\",\n",
    "\"--no-refine\",\n",
    "\n",
    "\"--xgandalf-sampling-pitch=n\"\n",
    "\"--xgandalf-grad-desc-iterations=n\"\n",
    "\"--xgandalf-tolerance=n\"\n",
    "\"--xgandalf-no-deviation-from-provided-cell\"\n",
    "\"--xgandalf-max-lattice-vector-length=n\"\n",
    "\"--xgandalf-min-lattice-vector-length=n\"\n",
    "\"--xgandalf-max-peaks=n\"\n",
    "\"--xgandalf-fast-execution\"\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Integration\n",
    "\"--fix-profile-radius=n\",\n",
    "\"--fix-divergence=n\",\n",
    "\"--integration=rings\",\n",
    "\"--int-radius=4,5,10\",\n",
    "\"--push-res=n\",\n",
    "\"--overpredict\",\n",
    "\"--cell-parameters-only\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Output\n",
    "\"--no-non-hits-in-stream\",\n",
    "\"--no-peaks-in-stream\",\n",
    "\"--no-refls-in-stream\",\n",
    "\"--serial-offset\n",
    "\"\"\"\n",
    "\n",
    "gandalf_iterator(x, y, geomfile_path, cellfile_path, input_path, output_file_base, num_threads, max_radius=max_radius, step=step, extra_flags=extra_flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the IQM with chosen weights for all frames across all index results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating multiple stream files with weights: (1, 1, 1, 1, 1, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks in LTA_-513.3_-512.1.stream: 100%|██████████| 100/100 [00:04<00:00, 20.63chunk/s]\n",
      "Processing chunks in LTA_-513.3_-513.1.stream: 100%|██████████| 100/100 [00:05<00:00, 19.62chunk/s]\n",
      "Processing chunks in LTA_-513.1_-511.9.stream: 100%|██████████| 100/100 [00:05<00:00, 17.96chunk/s]\n",
      "Processing chunks in LTA_-512.9_-512.1.stream: 100%|██████████| 100/100 [00:08<00:00, 11.28chunk/s]\n",
      "Processing chunks in LTA_-512.9_-513.1.stream: 100%|██████████| 100/100 [00:10<00:00,  9.93chunk/s]\n",
      "Processing chunks in LTA_-512.7_-512.9.stream: 100%|██████████| 100/100 [00:11<00:00,  8.45chunk/s]\n",
      "Processing chunks in LTA_-512.3_-512.9.stream: 100%|██████████| 100/100 [00:12<00:00,  8.28chunk/s]\n",
      "Processing chunks in LTA_-512.7_-512.5.stream: 100%|██████████| 100/100 [00:12<00:00,  7.79chunk/s]\n",
      "Processing chunks in LTA_-513.3_-512.3.stream: 100%|██████████| 100/100 [00:07<00:00, 12.84chunk/s]\n",
      "Processing chunks in LTA_-512.1_-511.7.stream: 100%|██████████| 100/100 [00:04<00:00, 21.95chunk/s]\n",
      "Processing chunks in LTA_-512.9_-513.3.stream: 100%|██████████| 100/100 [00:06<00:00, 16.22chunk/s]\n",
      "Processing chunks in LTA_-512.3_-512.5.stream: 100%|██████████| 100/100 [00:13<00:00,  7.51chunk/s]\n",
      "Processing chunks in LTA_-512.7_-512.7.stream: 100%|██████████| 100/100 [00:13<00:00,  7.60chunk/s]\n",
      "Processing chunks in LTA_-512.3_-513.3.stream: 100%|██████████| 100/100 [00:07<00:00, 13.25chunk/s]\n",
      "Processing chunks in LTA_-512.3_-512.7.stream: 100%|██████████| 100/100 [00:12<00:00,  7.79chunk/s]\n",
      "Processing chunks in LTA_-512.9_-512.3.stream: 100%|██████████| 100/100 [00:12<00:00,  7.87chunk/s]\n",
      "Processing chunks in LTA_-512.5_-511.7.stream: 100%|██████████| 100/100 [00:06<00:00, 16.32chunk/s]\n",
      "Processing chunks in LTA_-513.3_-512.7.stream: 100%|██████████| 100/100 [00:06<00:00, 14.41chunk/s]\n",
      "Processing chunks in LTA_-512.3_-512.3.stream: 100%|██████████| 100/100 [00:11<00:00,  8.53chunk/s]\n",
      "Processing chunks in LTA_-512.7_-513.3.stream: 100%|██████████| 100/100 [00:06<00:00, 14.98chunk/s]\n",
      "Processing chunks in LTA_-511.5_-512.5.stream: 100%|██████████| 100/100 [00:05<00:00, 16.79chunk/s]\n",
      "Processing chunks in LTA_-512.7_-512.3.stream: 100%|██████████| 100/100 [00:12<00:00,  8.13chunk/s]\n",
      "Processing chunks in LTA_-512.1_-511.9.stream: 100%|██████████| 100/100 [00:06<00:00, 15.67chunk/s]\n",
      "Processing chunks in LTA_-512.9_-512.7.stream: 100%|██████████| 100/100 [00:12<00:00,  8.24chunk/s]\n",
      "Processing chunks in LTA_-512.9_-512.9.stream: 100%|██████████| 100/100 [00:11<00:00,  8.90chunk/s]\n",
      "Processing chunks in LTA_-512.3_-513.1.stream: 100%|██████████| 100/100 [00:08<00:00, 11.75chunk/s]\n",
      "Processing chunks in LTA_-512.3_-512.1.stream: 100%|██████████| 100/100 [00:09<00:00, 11.08chunk/s]\n",
      "Processing chunks in LTA_-512.5_-511.5.stream: 100%|██████████| 100/100 [00:03<00:00, 28.01chunk/s]\n",
      "Processing chunks in LTA_-512.9_-512.5.stream: 100%|██████████| 100/100 [00:12<00:00,  7.91chunk/s]\n",
      "Processing chunks in LTA_-511.9_-511.9.stream: 100%|██████████| 100/100 [00:04<00:00, 21.88chunk/s]\n",
      "Processing chunks in LTA_-513.3_-512.5.stream: 100%|██████████| 100/100 [00:07<00:00, 13.41chunk/s]\n",
      "Processing chunks in LTA_-512.7_-513.1.stream: 100%|██████████| 100/100 [00:09<00:00, 10.86chunk/s]\n",
      "Processing chunks in LTA_-513.3_-512.9.stream: 100%|██████████| 100/100 [00:07<00:00, 13.01chunk/s]\n",
      "Processing chunks in LTA_-512.5_-511.9.stream: 100%|██████████| 100/100 [00:07<00:00, 13.37chunk/s]\n",
      "Processing chunks in LTA_-511.7_-512.7.stream: 100%|██████████| 100/100 [00:07<00:00, 13.03chunk/s]\n",
      "Processing chunks in LTA_-512.7_-512.1.stream: 100%|██████████| 100/100 [00:11<00:00,  8.75chunk/s]\n",
      "Processing chunks in LTA_-511.9_-512.3.stream: 100%|██████████| 100/100 [00:07<00:00, 13.48chunk/s]\n",
      "Processing chunks in LTA_-513.1_-512.7.stream: 100%|██████████| 100/100 [00:10<00:00,  9.95chunk/s]\n",
      "Processing chunks in LTA_-512.7_-511.7.stream: 100%|██████████| 100/100 [00:04<00:00, 22.86chunk/s]\n",
      "Processing chunks in LTA_-511.9_-513.3.stream: 100%|██████████| 100/100 [00:06<00:00, 14.70chunk/s]\n",
      "Processing chunks in LTA_-512.5_-513.3.stream: 100%|██████████| 100/100 [00:06<00:00, 16.58chunk/s]\n",
      "Processing chunks in LTA_-512.3_-511.7.stream: 100%|██████████| 100/100 [00:05<00:00, 19.83chunk/s]\n",
      "Processing chunks in LTA_-512.1_-513.3.stream: 100%|██████████| 100/100 [00:07<00:00, 12.66chunk/s]\n",
      "Processing chunks in LTA_-512.7_-511.9.stream: 100%|██████████| 100/100 [00:05<00:00, 17.75chunk/s]\n",
      "Processing chunks in LTA_-512.5_-512.3.stream: 100%|██████████| 100/100 [00:11<00:00,  8.44chunk/s]\n",
      "Processing chunks in LTA_-511.9_-512.1.stream: 100%|██████████| 100/100 [00:06<00:00, 16.56chunk/s]\n",
      "Processing chunks in LTA_-512.5_-513.1.stream: 100%|██████████| 100/100 [00:08<00:00, 11.58chunk/s]\n",
      "Processing chunks in LTA_-512.1_-512.3.stream: 100%|██████████| 100/100 [00:09<00:00, 10.04chunk/s]\n",
      "Processing chunks in LTA_-513.1_-512.9.stream: 100%|██████████| 100/100 [00:10<00:00,  9.89chunk/s]\n",
      "Processing chunks in LTA_-512.5_-512.1.stream: 100%|██████████| 100/100 [00:10<00:00,  9.32chunk/s]\n",
      "Processing chunks in LTA_-512.3_-511.9.stream: 100%|██████████| 100/100 [00:05<00:00, 17.10chunk/s]\n",
      "Processing chunks in LTA_-513.5_-512.5.stream: 100%|██████████| 100/100 [00:05<00:00, 17.07chunk/s]\n",
      "Processing chunks in LTA_-511.9_-513.1.stream: 100%|██████████| 100/100 [00:07<00:00, 13.08chunk/s]\n",
      "Processing chunks in LTA_-513.1_-512.5.stream: 100%|██████████| 100/100 [00:08<00:00, 11.28chunk/s]\n",
      "Processing chunks in LTA_-512.1_-512.1.stream: 100%|██████████| 100/100 [00:06<00:00, 14.84chunk/s]\n",
      "Processing chunks in LTA_-512.5_-513.5.stream: 100%|██████████| 100/100 [00:04<00:00, 21.55chunk/s]\n",
      "Processing chunks in LTA_-512.1_-513.1.stream: 100%|██████████| 100/100 [00:08<00:00, 11.41chunk/s]\n",
      "Processing chunks in LTA_-511.7_-512.5.stream: 100%|██████████| 100/100 [00:08<00:00, 12.36chunk/s]\n",
      "Processing chunks in LTA_-511.7_-512.9.stream: 100%|██████████| 100/100 [00:07<00:00, 12.74chunk/s]\n",
      "Processing chunks in LTA_-513.3_-511.9.stream: 100%|██████████| 100/100 [00:04<00:00, 20.41chunk/s]\n",
      "Processing chunks in LTA_-512.1_-512.5.stream: 100%|██████████| 100/100 [00:10<00:00,  9.53chunk/s]\n",
      "Processing chunks in LTA_-512.1_-512.9.stream: 100%|██████████| 100/100 [00:11<00:00,  8.64chunk/s]\n",
      "Processing chunks in LTA_-511.9_-512.5.stream: 100%|██████████| 100/100 [00:08<00:00, 11.48chunk/s]\n",
      "Processing chunks in LTA_-513.1_-512.1.stream: 100%|██████████| 100/100 [00:07<00:00, 13.88chunk/s]\n",
      "Processing chunks in LTA_-513.1_-513.1.stream: 100%|██████████| 100/100 [00:08<00:00, 11.18chunk/s]\n",
      "Processing chunks in LTA_-512.5_-512.5.stream: 100%|██████████| 100/100 [00:12<00:00,  8.14chunk/s]\n",
      "Processing chunks in LTA_-511.9_-512.9.stream: 100%|██████████| 100/100 [00:08<00:00, 11.70chunk/s]\n",
      "Processing chunks in LTA_-511.7_-512.3.stream: 100%|██████████| 100/100 [00:04<00:00, 22.30chunk/s]\n",
      "Processing chunks in LTA_-512.9_-511.7.stream: 100%|██████████| 100/100 [00:04<00:00, 21.22chunk/s]\n",
      "Processing chunks in LTA_-511.7_-512.1.stream: 100%|██████████| 100/100 [00:05<00:00, 17.11chunk/s]\n",
      "Processing chunks in LTA_-512.9_-511.9.stream: 100%|██████████| 100/100 [00:06<00:00, 14.36chunk/s]\n",
      "Processing chunks in LTA_-513.1_-513.3.stream: 100%|██████████| 100/100 [00:05<00:00, 16.96chunk/s]\n",
      "Processing chunks in LTA_-512.5_-512.9.stream: 100%|██████████| 100/100 [00:10<00:00,  9.41chunk/s]\n",
      "Processing chunks in LTA_-513.1_-512.3.stream: 100%|██████████| 100/100 [00:06<00:00, 14.70chunk/s]\n",
      "Processing chunks in LTA_-512.1_-512.7.stream: 100%|██████████| 100/100 [00:08<00:00, 11.26chunk/s]\n",
      "Processing chunks in LTA_-511.9_-512.7.stream: 100%|██████████| 100/100 [00:06<00:00, 16.04chunk/s]\n",
      "Processing chunks in LTA_-512.5_-512.7.stream: 100%|██████████| 100/100 [00:07<00:00, 13.72chunk/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined metrics CSV written to /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/metric_values_IQM_1_1_1_1_1_1.csv\n",
      "Best results stream file written to /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1.stream\n"
     ]
    }
   ],
   "source": [
    "from automate_evaluation import automate_evaluation\n",
    "\n",
    "# Enter folder with stream file results from indexamajig. \n",
    "# Note that ALL stream files in the folder will be processed.\n",
    "stream_file_folder = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2\" \n",
    "\n",
    "weights_list = [\n",
    "    (1, 1, 1, 1, 1, 1)\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "Each weight corresponds to one of the six metrics used in calculating the combined IQM value.\n",
    "The combined IQM is computed by first normalizing each metric across all stream files, then \n",
    "multiplying each normalized metric by its assigned weight, and finally summing the results.\n",
    "The order (or keys) of the weights must match the following metrics:\n",
    "\n",
    "- 'weighted_rmsd'\n",
    "- 'fraction_outliers'\n",
    "- 'length_deviation'\n",
    "- 'angle_deviation'\n",
    "- 'peak_ratio'\n",
    "- 'percentage_indexed'\n",
    "\n",
    "Multiple weight combinations can be specified if needed.\n",
    "\"\"\"\n",
    "\n",
    "automate_evaluation(stream_file_folder, weights_list, indexing_tolerance=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the best results stream file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partialator for stream file: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1.stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partialator Progress:   0%|          | 0/7 [00:00<?, ?Residual/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partialator Progress: 100%|██████████| 7/7 [00:01<00:00,  6.78Residual/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partialator completed for stream file: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1.stream\n",
      "Merging done. Results are in: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from merge import merge\n",
    "\n",
    "stream_file = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1.stream\"\n",
    "pointgroup = \"m-3m\"\n",
    "num_threads = 24\n",
    "iterations = 5\n",
    "\n",
    "output_dir = merge(\n",
    "    stream_file,\n",
    "    pointgroup=pointgroup,\n",
    "    num_threads=num_threads,\n",
    "    iterations=iterations,\n",
    ")\n",
    "\n",
    "if output_dir is not None:\n",
    "    print(\"Merging done. Results are in:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to shelx compatible .hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting crystfel.hkl to shelx.hkl in directory: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\n",
      "[INFO] Conversion to shelx.hkl completed successfully in: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter/shelx\n"
     ]
    }
   ],
   "source": [
    "from convert_hkl_crystfel_to_shelx import convert_hkl_crystfel_to_shelx \n",
    "output_dir = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\"\n",
    "convert_hkl_crystfel_to_shelx(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to mtz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Converting crystfel.hkl to output.mtz in directory: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\n",
      "[INFO] Conversion to output.mtz completed successfully in: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\n"
     ]
    }
   ],
   "source": [
    "from convert_hkl_to_mtz import convert_hkl_to_mtz\n",
    "cellfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTA.cell\"  # If defined above comment out this line\n",
    "convert_hkl_to_mtz(output_dir, cellfile_path=cellfile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyxem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
