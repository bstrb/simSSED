{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipyfilechooser import FileChooser\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# -- Your helper function that computes center for a single frame --\n",
    "from helpers import process_image_full\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# IRLS FIT HELPERS\n",
    "# =============================================================================\n",
    "def poly_design_matrix(x, degree=3):\n",
    "    \"\"\"\n",
    "    Given an array x of shape (N,), produce the design matrix for a polynomial\n",
    "    of 'degree'.\n",
    "    E.g., for degree=3, returns [1, x, x^2, x^3].\n",
    "    Shape => (N, degree+1).\n",
    "    \"\"\"\n",
    "    # We'll build [1, x, x^2, ..., x^degree]\n",
    "    X = np.ones((len(x), degree+1), dtype=np.float64)\n",
    "    for d in range(1, degree+1):\n",
    "        X[:, d] = x**d\n",
    "    return X\n",
    "\n",
    "def irls_fit_poly(x, y, degree=3, max_iter=50, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Fits a polynomial of given degree to data (x, y) using IRLS for robust regression.\n",
    "\n",
    "    Returns:\n",
    "       coeffs: (degree+1,) polynomial coefficients [c0, c1, ..., cD]\n",
    "    \"\"\"\n",
    "    # Build the design matrix\n",
    "    X = poly_design_matrix(x, degree=degree)\n",
    "    # Start with a normal (least-squares) solution as initial guess\n",
    "    # Using linear solve:  (X^T W X) b = X^T W y\n",
    "    # For initial guess, W = I\n",
    "    beta = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "\n",
    "    # IRLS loop\n",
    "    for _ in range(max_iter):\n",
    "        # Predict\n",
    "        y_pred = X @ beta\n",
    "        residuals = y - y_pred\n",
    "        \n",
    "        # We'll use a simple robust weighting function: e.g. Huber or Cauchy\n",
    "        # For demonstration, let's do something fairly standard like a Huber-like approach.\n",
    "        # We'll define an 'epsilon' scale factor.\n",
    "        # A more formal approach would estimate scale from median absolute deviation.\n",
    "        epsilon = 1.5 * np.median(np.abs(residuals))  # scale estimate\n",
    "        if epsilon < 1e-9:\n",
    "            # data might be degenerate or no variation\n",
    "            break\n",
    "\n",
    "        # Huber-like weights\n",
    "        # w_i = 1 if |res| < epsilon, else epsilon / |res|\n",
    "        abs_res = np.abs(residuals)\n",
    "        w = np.where(abs_res <= epsilon, 1.0, epsilon / abs_res)\n",
    "        # Avoid dividing by zero\n",
    "        w[abs_res < 1e-12] = 1.0\n",
    "\n",
    "        # Build diagonal weight matrix\n",
    "        W = np.diag(w)\n",
    "        # Weighted least squares update\n",
    "        XTWX = X.T @ W @ X\n",
    "        XTWy = X.T @ W @ y\n",
    "        new_beta = np.linalg.lstsq(XTWX, XTWy, rcond=None)[0]\n",
    "\n",
    "        # Check convergence\n",
    "        if np.linalg.norm(new_beta - beta) < tol:\n",
    "            beta = new_beta\n",
    "            break\n",
    "\n",
    "        beta = new_beta\n",
    "\n",
    "    return beta\n",
    "\n",
    "def poly_predict(x, coeffs):\n",
    "    \"\"\"\n",
    "    Evaluate polynomial with 'coeffs' on domain x.\n",
    "    \"\"\"\n",
    "    degree = len(coeffs) - 1\n",
    "    X = poly_design_matrix(x, degree=degree)\n",
    "    return X @ coeffs\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# ADAPTIVE SAMPLING LOGIC\n",
    "# =============================================================================\n",
    "def adaptive_sampling(\n",
    "    dataset_images, mask,\n",
    "    threshold,\n",
    "    max_iters,\n",
    "    step_size,\n",
    "    n_steps,\n",
    "    n_wedges,\n",
    "    n_rad_bins,\n",
    "    plot_profiles,\n",
    "    desired_accuracy=0.5,\n",
    "    max_refine_iterations=5,\n",
    "    init_stride=100,\n",
    "    poly_degree=3,\n",
    "    chunk_size=100\n",
    "):\n",
    "    \"\"\"\n",
    "    Overall logic:\n",
    "    1) Start with frames = range(0, n_frames, init_stride).\n",
    "    2) Compute centers for those frames.\n",
    "    3) Fit polynomial (IRLS) for x(t) and y(t).\n",
    "    4) Check residual error. If > desired_accuracy, subdivide intervals that are too large.\n",
    "    5) Repeat until error < desired_accuracy or max_refine_iterations reached.\n",
    "    6) Return final polynomial coefficients for x and y, plus the final list of sampled frames & centers.\n",
    "    \"\"\"\n",
    "\n",
    "    n_frames = dataset_images.shape[0]\n",
    "    frames_chosen = list(range(0, n_frames, init_stride))  # initial guess\n",
    "    if frames_chosen[-1] != n_frames - 1:\n",
    "        frames_chosen.append(n_frames - 1)  # ensure last frame is included\n",
    "\n",
    "    frames_chosen = sorted(set(frames_chosen))  # unique & sorted\n",
    "\n",
    "    # We'll store centers in a dictionary: frame_idx -> (x, y)\n",
    "    known_centers = {}\n",
    "\n",
    "    def get_centers_for_frames(frames_needed):\n",
    "        \"\"\"Compute centers for frames in frames_needed (which might be new).\n",
    "           We'll do chunked reading, but not with a Pool for the entire set (for clarity).\n",
    "           You can adapt for full parallelism if desired.\n",
    "        \"\"\"\n",
    "        frames_needed = sorted(set(frames_needed))\n",
    "        results = {}\n",
    "        \n",
    "        # We can do chunk-wise reading to avoid reading everything at once\n",
    "        with tqdm(total=len(frames_needed), desc=\"Computing new centers\") as pbar:\n",
    "            i_next = 0  # index over frames_needed\n",
    "            while i_next < len(frames_needed):\n",
    "                fstart = frames_needed[i_next]\n",
    "                # read a chunk from fstart to fstart+chunk_size\n",
    "                cstart = fstart\n",
    "                cend = min(fstart + chunk_size, n_frames)\n",
    "                \n",
    "                # gather frames within [cstart, cend)\n",
    "                frames_in_chunk = []\n",
    "                while i_next < len(frames_needed) and frames_needed[i_next] < cend:\n",
    "                    frames_in_chunk.append(frames_needed[i_next])\n",
    "                    i_next += 1\n",
    "                \n",
    "                if len(frames_in_chunk) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # read images\n",
    "                images_chunk = dataset_images[cstart:cend].astype(np.float32)\n",
    "                \n",
    "                # prepare arguments for the pool\n",
    "                arg_list = []\n",
    "                for fidx in frames_in_chunk:\n",
    "                    local_idx = fidx - cstart\n",
    "                    arg_list.append((\n",
    "                        fidx,\n",
    "                        images_chunk[local_idx],\n",
    "                        mask,\n",
    "                        threshold,\n",
    "                        max_iters,\n",
    "                        step_size,\n",
    "                        n_steps,\n",
    "                        n_wedges,\n",
    "                        n_rad_bins,\n",
    "                        plot_profiles\n",
    "                    ))\n",
    "                \n",
    "                # process in parallel\n",
    "                chunk_results = []\n",
    "                with Pool() as pool:\n",
    "                    for res in pool.imap_unordered(process_image_full, arg_list):\n",
    "                        chunk_results.append(res)\n",
    "                        pbar.update(1)\n",
    "                \n",
    "                # store\n",
    "                for (frame_num, (cy, cx)) in chunk_results:\n",
    "                    results[frame_num] = (cx, cy)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    refine_iteration = 0\n",
    "    while refine_iteration < max_refine_iterations:\n",
    "        # Find which frames we haven't computed yet\n",
    "        frames_to_compute = [f for f in frames_chosen if f not in known_centers]\n",
    "\n",
    "        # Compute new centers\n",
    "        if len(frames_to_compute) > 0:\n",
    "            new_results = get_centers_for_frames(frames_to_compute)\n",
    "            known_centers.update(new_results)\n",
    "\n",
    "        # Build arrays for IRLS\n",
    "        # frames_chosen is sorted\n",
    "        chosen_frames_array = np.array(frames_chosen, dtype=np.float32)\n",
    "        chosen_centers_array = np.array([known_centers[f] for f in frames_chosen], dtype=np.float32)\n",
    "        # chosen_centers_array[:, 0] = x(t), chosen_centers_array[:, 1] = y(t)\n",
    "\n",
    "        # Fit polynomial for X(t)\n",
    "        x_poly = irls_fit_poly(chosen_frames_array, chosen_centers_array[:, 0],\n",
    "                               degree=poly_degree)\n",
    "        # Fit polynomial for Y(t)\n",
    "        y_poly = irls_fit_poly(chosen_frames_array, chosen_centers_array[:, 1],\n",
    "                               degree=poly_degree)\n",
    "\n",
    "        # Evaluate error on the chosen frames\n",
    "        x_pred = poly_predict(chosen_frames_array, x_poly)\n",
    "        y_pred = poly_predict(chosen_frames_array, y_poly)\n",
    "        dx = chosen_centers_array[:,0] - x_pred\n",
    "        dy = chosen_centers_array[:,1] - y_pred\n",
    "        errors = np.sqrt(dx*dx + dy*dy)\n",
    "\n",
    "        max_error = errors.max()\n",
    "        print(f\"[Refine #{refine_iteration}] Max error among sampled frames: {max_error:.3f}\")\n",
    "\n",
    "        if max_error < desired_accuracy:\n",
    "            print(\"Desired accuracy reached. Stopping refinement.\")\n",
    "            break\n",
    "\n",
    "        # Otherwise, refine: find intervals with large error and subdivide\n",
    "        new_frames = []\n",
    "        for i in range(len(chosen_frames_array)-1):\n",
    "            f1 = frames_chosen[i]\n",
    "            f2 = frames_chosen[i+1]\n",
    "            e1 = errors[i]\n",
    "            e2 = errors[i+1]\n",
    "            # If either endpoint has an error > desired_accuracy, we'll add a midpoint sample\n",
    "            if e1 > desired_accuracy or e2 > desired_accuracy:\n",
    "                mid = (f1 + f2)//2\n",
    "                if mid not in frames_chosen and mid not in new_frames and mid != f1 and mid != f2:\n",
    "                    new_frames.append(mid)\n",
    "\n",
    "        if len(new_frames) == 0:\n",
    "            print(\"No additional frames to add, but error still above threshold. Stopping.\")\n",
    "            break\n",
    "\n",
    "        frames_chosen = sorted(set(frames_chosen + new_frames))\n",
    "        refine_iteration += 1\n",
    "\n",
    "    # Return final polynomial coefficients + final sample\n",
    "    return {\n",
    "        \"frames_sampled\": frames_chosen,\n",
    "        \"centers_sampled\": np.array([known_centers[f] for f in frames_chosen]),\n",
    "        \"poly_x\": x_poly,\n",
    "        \"poly_y\": y_poly\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# WIDGETS FOR UI\n",
    "# =============================================================================\n",
    "\n",
    "# Create file chooser widgets for the image and mask files.\n",
    "image_file_chooser = FileChooser(\"/Users/xiaodong/Desktop/UOX-data/UOX1_sub/\", filename=\"UOX1_sub.h5\")\n",
    "# image_file_chooser = FileChooser(os.getcwd())\n",
    "image_file_chooser.title = \"Select H5 Image File\"\n",
    "image_file_chooser.filter_pattern = \"*.h5\"\n",
    "\n",
    "mask_file_chooser = FileChooser(\"/Users/xiaodong/mask/\", filename=\"pxmask.h5\")\n",
    "# mask_file_chooser = FileChooser(os.getcwd())\n",
    "mask_file_chooser.title = \"Select H5 Mask File\"\n",
    "mask_file_chooser.filter_pattern = \"*.h5\"\n",
    "\n",
    "threshold_widget = widgets.FloatText(\n",
    "    value=0.1,\n",
    "    description=\"Threshold:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "max_iters_widget = widgets.IntText(\n",
    "    value=10,\n",
    "    description=\"Max Iters:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "step_size_widget = widgets.IntText(\n",
    "    value=1,\n",
    "    description=\"Step Size:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "n_steps_widget = widgets.IntText(\n",
    "    value=5,\n",
    "    description=\"n_steps:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "n_wedges_widget = widgets.IntText(\n",
    "    value=4,\n",
    "    description=\"n_wedges:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "n_rad_bins_widget = widgets.IntText(\n",
    "    value=100,\n",
    "    description=\"n_rad_bins:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "plot_profiles_widget = widgets.Checkbox(\n",
    "    value=False,\n",
    "    description=\"Plot Profiles\"\n",
    ")\n",
    "chunk_size_widget = widgets.IntText(\n",
    "    value=100,\n",
    "    description=\"Chunk Size:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "desired_accuracy_widget = widgets.FloatText(\n",
    "    value=0.5,\n",
    "    description=\"Desired Accuracy (pixels):\",\n",
    "    layout=widgets.Layout(width='250px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "max_refine_iters_widget = widgets.IntText(\n",
    "    value=5,\n",
    "    description=\"Max Refinements:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "initial_stride_widget = widgets.IntText(\n",
    "    value=100,\n",
    "    description=\"Initial Stride:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "poly_degree_widget = widgets.IntText(\n",
    "    value=3,\n",
    "    description=\"Poly Degree:\",\n",
    "    layout=widgets.Layout(width='200px'),\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "process_button = widgets.Button(\n",
    "    description=\"Process Images (Adaptive + IRLS)\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "\n",
    "processing_output = widgets.Output(layout={\n",
    "    'border': '1px solid black',\n",
    "    'padding': '5px',\n",
    "    'height': '400px',\n",
    "    'overflow_y': 'auto'\n",
    "})\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN CALLBACK\n",
    "# =============================================================================\n",
    "def on_process_button_clicked(b):\n",
    "    with processing_output:\n",
    "        clear_output()\n",
    "        image_file = image_file_chooser.selected\n",
    "        mask_file = mask_file_chooser.selected\n",
    "        \n",
    "        if not image_file:\n",
    "            print(\"Please select an image file.\")\n",
    "            return\n",
    "        if not mask_file:\n",
    "            print(\"Please select a mask file.\")\n",
    "            return\n",
    "        \n",
    "        threshold = threshold_widget.value\n",
    "        max_iters = max_iters_widget.value\n",
    "        step_size = step_size_widget.value\n",
    "        n_steps = n_steps_widget.value\n",
    "        n_wedges = n_wedges_widget.value\n",
    "        n_rad_bins = n_rad_bins_widget.value\n",
    "        plot_profiles = plot_profiles_widget.value\n",
    "        chunk_size = chunk_size_widget.value\n",
    "\n",
    "        desired_accuracy = desired_accuracy_widget.value\n",
    "        max_refine_iters = max_refine_iters_widget.value\n",
    "        init_stride = initial_stride_widget.value\n",
    "        poly_degree = poly_degree_widget.value\n",
    "\n",
    "        csv_file = os.path.join(os.path.dirname(image_file), \"centers_adaptive_irls.csv\")\n",
    "        if os.path.exists(csv_file):\n",
    "            os.remove(csv_file)\n",
    "\n",
    "        print(f\"Opening H5: {image_file}\")\n",
    "        with h5py.File(image_file, 'r') as f_img, h5py.File(mask_file, 'r') as f_mask:\n",
    "            dataset_images = f_img['/entry/data/images']\n",
    "            mask = f_mask['/mask'][:].astype(bool)\n",
    "            n_frames = dataset_images.shape[0]\n",
    "            print(f\"Total frames: {n_frames}\")\n",
    "\n",
    "            # Adaptive sampling + IRLS\n",
    "            results = adaptive_sampling(\n",
    "                dataset_images, mask,\n",
    "                threshold=threshold,\n",
    "                max_iters=max_iters,\n",
    "                step_size=step_size,\n",
    "                n_steps=n_steps,\n",
    "                n_wedges=n_wedges,\n",
    "                n_rad_bins=n_rad_bins,\n",
    "                plot_profiles=plot_profiles,\n",
    "                desired_accuracy=desired_accuracy,\n",
    "                max_refine_iterations=max_refine_iters,\n",
    "                init_stride=init_stride,\n",
    "                poly_degree=poly_degree,\n",
    "                chunk_size=chunk_size\n",
    "            )\n",
    "\n",
    "            frames_sampled = results[\"frames_sampled\"]\n",
    "            centers_sampled = results[\"centers_sampled\"]  # Nx2 => (x, y)\n",
    "            px = results[\"poly_x\"]\n",
    "            py = results[\"poly_y\"]\n",
    "\n",
    "            # If you want a center estimate for *every* frame, \n",
    "            # simply evaluate the polynomial from 0..(n_frames-1).\n",
    "            all_frames = np.arange(n_frames, dtype=np.float32)\n",
    "            pred_x = poly_predict(all_frames, px)\n",
    "            pred_y = poly_predict(all_frames, py)\n",
    "\n",
    "            # Write to CSV\n",
    "            df = pd.DataFrame({\n",
    "                \"frame_number\": all_frames.astype(int),\n",
    "                \"center_x\": pred_x,\n",
    "                \"center_y\": pred_y\n",
    "            })\n",
    "            df.to_csv(csv_file, index=False)\n",
    "            print(f\"Final centers written to {csv_file}\")\n",
    "\n",
    "\n",
    "# Setup UI\n",
    "process_button.on_click(on_process_button_clicked)\n",
    "\n",
    "param_box = widgets.VBox([\n",
    "    threshold_widget,\n",
    "    max_iters_widget,\n",
    "    step_size_widget,\n",
    "    n_steps_widget,\n",
    "    n_wedges_widget,\n",
    "    n_rad_bins_widget,\n",
    "    plot_profiles_widget,\n",
    "    chunk_size_widget,\n",
    "    desired_accuracy_widget,\n",
    "    max_refine_iters_widget,\n",
    "    initial_stride_widget,\n",
    "    poly_degree_widget,\n",
    "])\n",
    "\n",
    "file_chooser_box = widgets.HBox([image_file_chooser, mask_file_chooser])\n",
    "ui = widgets.VBox([\n",
    "    widgets.HTML(\"<h2>Adaptive Sampling + IRLS</h2>\"),\n",
    "    file_chooser_box,\n",
    "    widgets.HTML(\"<h3>Processing Parameters</h3>\"),\n",
    "    param_box,\n",
    "    process_button,\n",
    "    widgets.HTML(\"<h3>Logs & Feedback</h3>\"),\n",
    "    processing_output\n",
    "])\n",
    "\n",
    "display(ui)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyxem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
