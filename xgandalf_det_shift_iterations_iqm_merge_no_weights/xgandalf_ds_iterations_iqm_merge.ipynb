{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the CrystFEL-based Processing Workflow\n",
    "\n",
    "This notebook implements a complete workflow for processing crystallography data using CrystFEL tools alongside custom scripts. It is designed to:\n",
    "  \n",
    "1. **Run Indexamajig** (`gandalf_iterator`)  \n",
    "   - Execute peak finding, indexing, and integration for each HDF5 file.\n",
    "   - Vary beam center coordinates on a radial grid (using defined maximum radius and step size).\n",
    "\n",
    "2. **Visualize Indexing Results**  \n",
    "   - Generate 3D histograms and 2D heatmaps to assess indexing performance.\n",
    "\n",
    "3. **Evaluate Index Metrics** (`automate_evaluation`)  \n",
    "   - Parse stream files to compute indexing quality metrics (IQMs) for each frame.\n",
    "   - Analyze metrics such as weighted RMSD, fraction of outliers, length and angle deviations, peak ratio, and percentage indexed.\n",
    "\n",
    "4. **Interactive IQM Metrics Dashboard**  \n",
    "   - Use interactive sliders and weight inputs to filter and combine metrics.\n",
    "   - Create/update a combined metric and display histograms for filtered results.\n",
    "\n",
    "5. **CSV-to-Stream Conversion**  \n",
    "   - Convert the filtered metrics CSV into a stream file using custom conversion scripts.\n",
    "\n",
    "6. **Merge Best Results** (`merge`)  \n",
    "   - Merge the best result stream file to refine cell parameters and symmetry.\n",
    "\n",
    "7. **Convert to Shelx-Compatible .hkl**  \n",
    "   - Transform the merged output to a Shelx-compatible format for further crystallographic analysis.\n",
    "\n",
    "8. **Convert to .mtz Format**  \n",
    "   - Prepare data for downstream crystallographic software by converting .hkl to .mtz.\n",
    "\n",
    "> **Pre-requisites:**  \n",
    "> Ensure that all preprocessing steps (peak finding, center refinement, etc.) have been completed and that the required tools and Python packages (CrystFEL, ipywidgets, matplotlib, etc.) are installed and properly configured before running the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ==============================================\n",
    "# Run indexamajig Iterations on a Circular Grid\n",
    "### Options for Peakfinding, Indexing and Integration\n",
    "# ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gandalf_radial_iterator import gandalf_iterator\n",
    "\n",
    "geomfile_path = \"/path/to/GEOM.geom\"       # .geom file\n",
    "cellfile_path = \"/path/to/CELL.cell\"          # .cell file\n",
    "\n",
    "input_path =   \"/path/to/h5/folder\"      # .h5 folder will also be output folder\n",
    "\n",
    "output_file_base = \"basename\"    # output files will be named output_file_base_xcoord_ycoord.h5\n",
    "\n",
    "num_threads = 24             # number of CPU threads to use\n",
    "\n",
    "\"\"\"Define the grid and maximum radius in pixels for iterations.\n",
    "As example max_radius = 1, step = 0.2 will give 81 iterations.\n",
    "Iterations will start at the center and move radially outwards.\n",
    "\"\"\"\n",
    "max_radius = 2             # maximum radius in pixels\n",
    "step = 0.5                 # grid granularity in pixels\n",
    "\n",
    "extra_flags=[\n",
    "# PEAKFINDING\n",
    "\"--no-revalidate\",\n",
    "\"--no-half-pixel-shift\",\n",
    "\"--peaks=cxi\", \n",
    "\"--min-peaks=15\",\n",
    "# INDEXING\n",
    "\"--indexing=xgandalf\",\n",
    "\"--tolerance=10,10,10,5\",\n",
    "\"--no-refine\",\n",
    "\"--xgandalf-sampling-pitch=5\",\n",
    "\"--xgandalf-grad-desc-iterations=1\",\n",
    "\"--xgandalf-tolerance=0.02\",\n",
    "# INTEGRATION\n",
    "\"--integration=rings\",\n",
    "\"--int-radius=4,5,9\",\n",
    "\"--fix-profile-radius=70000000\",\n",
    "# OUTPUT\n",
    "\"--no-non-hits-in-stream\",\n",
    "]\n",
    "\n",
    "\"\"\"Examples of extra flags(see crystfel documentation https://www.desy.de/~twhite/crystfel/manual-indexamajig.html):\n",
    "    \n",
    "    Peakfinding\n",
    "    \"--peaks=cxi\",\n",
    "    \"--peak-radius=inner,middle,outer\",\n",
    "    \"--min-peaks=n\",\n",
    "    \"--median-filter=n\",\n",
    "    \"--filter-noise\",\n",
    "    \"--no-revalidate\",\n",
    "    \"--no-half-pixel-shift\",\n",
    "\n",
    "    \"--peaks=peakfinder9\",\n",
    "    \"--min-snr=1\",\n",
    "    \"--min-snr-peak-pix=6\",\n",
    "    \"--min-snr-biggest-pix=1\",\n",
    "    \"--min-sig=9\",\n",
    "    \"--min-peak-over-neighbour=5\",\n",
    "    \"--local-bg-radius=5\",\n",
    "\n",
    "    \"--peaks=peakfinder8\",\n",
    "    \"--threshold=45\",\n",
    "    \"--min-snr=3\",\n",
    "    \"--min-pix-count=3\",\n",
    "    \"--max-pix-count=500\",\n",
    "    \"--local-bg-radius=9\",\n",
    "    \"--min-res=30\",\n",
    "    \"--max-res=500\",\n",
    "    \n",
    "    Indexing\n",
    "    \"--indexing=xgandalf\",\n",
    "\n",
    "    \"--tolerance=tol\"\n",
    "    \"--no-check-cell\",\n",
    "    \"--no-check-peaks\",\n",
    "    \"--multi\",\n",
    "    \"--no-retry\",\n",
    "    \"--no-refine\",\n",
    "\n",
    "    \"--xgandalf-sampling-pitch=n\"\n",
    "    \"--xgandalf-grad-desc-iterations=n\"\n",
    "    \"--xgandalf-tolerance=n\"\n",
    "    \"--xgandalf-no-deviation-from-provided-cell\"\n",
    "    \"--xgandalf-max-lattice-vector-length=n\"\n",
    "    \"--xgandalf-min-lattice-vector-length=n\"\n",
    "    \"--xgandalf-max-peaks=n\"\n",
    "\n",
    "    Integration\n",
    "    \"--fix-profile-radius=n\",\n",
    "    \"--integration=rings\",\n",
    "    \"--int-radius=4,5,10\",\n",
    "    \"--push-res=n\",\n",
    "    \"--overpredict\",\n",
    "\n",
    "    Output\n",
    "    \"--no-non-hits-in-stream\",\n",
    "    \"--no-peaks-in-stream\",\n",
    "    \"--no-refls-in-stream\",\n",
    "\"\"\"\n",
    "\n",
    "gandalf_iterator(geomfile_path, cellfile_path, input_path, output_file_base, num_threads, max_radius=max_radius, step=step, extra_flags=extra_flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Indexing Results: 3D Histogram & 2D Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from indexing_3d_histogram import plot3d_indexing_rate\n",
    "from indexing_center import indexing_heatmap\n",
    "\n",
    "output_folder = \"path/to/output/folder\"\n",
    "plot3d_indexing_rate(output_folder)\n",
    "indexing_heatmap(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ==============================================\n",
    "# Process Indexing Metrics Across All Stream Files\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from process_indexing_metrics import process_indexing_metrics\n",
    "\n",
    "# Enter folder with stream file results from indexamajig. \n",
    "# Note that ALL stream files in the folder will be processed.\n",
    "\n",
    "stream_file_folder = \"path/to/stream/folder\"\n",
    "wrmsd_tolerance = 2.0\n",
    "indexing_tolerance = 4.0\n",
    "\n",
    "\"\"\"\n",
    "wrmsd_tolerance :\n",
    "The number of standard deviations away from the mean weighted RMSD for a chunk to be considered an outlier. Default factor is 2.0.\n",
    "\n",
    "indexing_tolerance :\n",
    "The maximum deviation in pixels between observed and predicted peak positions for a peak to be considered indexed. Default is 1.0 pixel.\n",
    "\n",
    "The following metrics will be evaluated for analysis in the next step:\n",
    "\n",
    "- 'weighted_rmsd'\n",
    "- 'fraction_outliers'\n",
    "- 'length_deviation'\n",
    "- 'angle_deviation'\n",
    "- 'peak_ratio'\n",
    "- 'percentage_indexed'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "process_indexing_metrics(stream_file_folder, wrmsd_tolerance=wrmsd_tolerance, indexing_tolerance=indexing_tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Interactive Metrics Analysis and CSV-to-Stream Conversion\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the normalized metrics CSV file and run this cell to start the interactive IQM tool\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import csv_to_stream  \n",
    "\n",
    "from interactive_iqm import (\n",
    "    read_metric_csv,\n",
    "    select_best_results_by_event,\n",
    "    get_metric_ranges,\n",
    "    create_combined_metric,\n",
    "    filter_rows,\n",
    "    write_filtered_csv\n",
    ")\n",
    "\n",
    "#################################\n",
    "# 1) PATHS\n",
    "#################################\n",
    "CSV_PATH = \"path/to/normalized_metrics.csv\"\n",
    "FILTERED_CSV_PATH = os.path.join(os.path.dirname(CSV_PATH), 'filtered_metrics.csv')\n",
    "\n",
    "#################################\n",
    "# 2) Read the CSV (group by event)\n",
    "#################################\n",
    "grouped_data = read_metric_csv(CSV_PATH, group_by_event=True)\n",
    "\n",
    "#################################\n",
    "# 3) If you have multiple rows per event, pick \"best\" row\n",
    "#################################\n",
    "best_rows = select_best_results_by_event(grouped_data, sort_metric='weighted_rmsd')\n",
    "\n",
    "#################################\n",
    "# 4) Metrics in your CSV\n",
    "#################################\n",
    "metrics_in_order = [\n",
    "    'weighted_rmsd',\n",
    "    'fraction_outliers',\n",
    "    'length_deviation',\n",
    "    'angle_deviation',\n",
    "    'peak_ratio',\n",
    "    'percentage_unindexed'\n",
    "]\n",
    "\n",
    "#################################\n",
    "# 5) Create threshold sliders for each original metric\n",
    "#################################\n",
    "ranges_dict = get_metric_ranges(best_rows, metrics=metrics_in_order)\n",
    "metric_sliders = {}\n",
    "\n",
    "def create_slider(metric_name, min_val, max_val):\n",
    "    # We'll do a ≤ filter, so default slider to max => \"include all\"\n",
    "    default_val = max_val\n",
    "    step = (max_val - min_val) / 100.0 if max_val != min_val else 0.01\n",
    "    slider = widgets.FloatSlider(\n",
    "        value=default_val,\n",
    "        min=min_val,\n",
    "        max=max_val,\n",
    "        step=step,\n",
    "        description=f\"{metric_name} ≤\"\n",
    "    )\n",
    "    return slider\n",
    "\n",
    "for metric in metrics_in_order:\n",
    "    mn, mx = ranges_dict[metric]\n",
    "    metric_sliders[metric] = create_slider(metric, mn, mx)\n",
    "\n",
    "#################################\n",
    "# 6) Text fields for per-metric weights to create a combined metric\n",
    "#################################\n",
    "weight_text_fields = {}\n",
    "for metric in metrics_in_order:\n",
    "    weight_text_fields[metric] = widgets.FloatText(\n",
    "        value=0.0,  # default to 0 => skip that metric in combined sum\n",
    "        description=f\"Weight for {metric}\",\n",
    "        style={\"description_width\": \"initial\"} \n",
    "    )\n",
    "\n",
    "#################################\n",
    "# 7) A slider to threshold the combined metric\n",
    "#################################\n",
    "combined_metric_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description=\"combined_metric ≤\"\n",
    ")\n",
    "\n",
    "#################################\n",
    "# 8) Button & function to create/update combined metric\n",
    "#################################\n",
    "def create_or_update_combined_metric(_):\n",
    "    \"\"\"\n",
    "    Read user-entered weights for each metric, compute 'combined_metric' \n",
    "    for best_rows, and update the combined_metric_slider's min/max/value.\n",
    "    \"\"\"\n",
    "    selected_metrics = []\n",
    "    weights_list = []\n",
    "    for m in metrics_in_order:\n",
    "        w = weight_text_fields[m].value\n",
    "        selected_metrics.append(m)\n",
    "        weights_list.append(w)\n",
    "\n",
    "    create_combined_metric(\n",
    "        rows=best_rows,\n",
    "        metrics_to_combine=selected_metrics,\n",
    "        weights=weights_list,\n",
    "        new_metric_name=\"combined_metric\"\n",
    "    )\n",
    "\n",
    "    combined_vals = [r[\"combined_metric\"] for r in best_rows]\n",
    "    cmin, cmax = min(combined_vals), max(combined_vals)\n",
    "\n",
    "    with combined_metric_slider.hold_trait_notifications():\n",
    "        current_val = combined_metric_slider.value\n",
    "        if current_val < cmin or current_val > cmax:\n",
    "            current_val = cmax  # or choose cmin if preferred\n",
    "        combined_metric_slider.min = cmin\n",
    "        combined_metric_slider.max = cmax\n",
    "        combined_metric_slider.value = current_val\n",
    "\n",
    "    print(\"Created/updated 'combined_metric' using user-entered weights.\")\n",
    "\n",
    "create_combined_button = widgets.Button(description=\"Create Combined Metric\")\n",
    "create_combined_button.on_click(create_or_update_combined_metric)\n",
    "\n",
    "#################################\n",
    "# 9) Create separate output widgets for each row of histograms, CSV path message, and CSV-to-stream conversion\n",
    "#################################\n",
    "combined_out = widgets.Output()\n",
    "csv_path_out = widgets.Output()\n",
    "wrmsd_frac_out = widgets.Output()\n",
    "length_angle_out = widgets.Output()\n",
    "peak_unindexed_out = widgets.Output()\n",
    "csv_to_stream_out = widgets.Output()  # New output widget for CSV-to-stream conversion messages\n",
    "\n",
    "#################################\n",
    "# 10) Button to apply thresholds, update histograms, and write CSV\n",
    "#################################\n",
    "filter_button = widgets.Button(description=\"Apply Thresholds & Show Histograms\")\n",
    "\n",
    "def on_filter_clicked(_):\n",
    "    # Clear previous outputs in all rows\n",
    "    combined_out.clear_output()\n",
    "    csv_path_out.clear_output()\n",
    "    wrmsd_frac_out.clear_output()\n",
    "    length_angle_out.clear_output()\n",
    "    peak_unindexed_out.clear_output()\n",
    "    csv_to_stream_out.clear_output()\n",
    "    \n",
    "    # Build thresholds from slider values on the original metrics\n",
    "    thresholds = {m: metric_sliders[m].value for m in metrics_in_order}\n",
    "    if \"combined_metric\" in best_rows[0]:\n",
    "        thresholds[\"combined_metric\"] = combined_metric_slider.value\n",
    "\n",
    "    filtered = filter_rows(best_rows, thresholds)\n",
    "    \n",
    "    # Print filtering summary into csv_path_out\n",
    "    with csv_path_out:\n",
    "        print(f\"Filtering... {len(best_rows)} rows -> {len(filtered)} pass thresholds.\\n\")\n",
    "    \n",
    "    if not filtered:\n",
    "        with csv_path_out:\n",
    "            print(\"No rows passed the thresholds, skipping histograms.\")\n",
    "        return\n",
    "\n",
    "    # Write CSV of the filtered rows\n",
    "    write_filtered_csv(filtered, FILTERED_CSV_PATH)\n",
    "    with csv_path_out:\n",
    "        print(f\"Filtered CSV (including 'combined_metric' if created) written to:\\n  {FILTERED_CSV_PATH}\\n\")\n",
    "    \n",
    "    # Row 1: Combined metric histogram\n",
    "    with combined_out:\n",
    "        if \"combined_metric\" in filtered[0]:\n",
    "            plt.figure()\n",
    "            values = [r[\"combined_metric\"] for r in filtered]\n",
    "            plt.hist(values, bins=20)\n",
    "            plt.title(\"Histogram of combined_metric\")\n",
    "            plt.xlabel(\"combined_metric\")\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"No 'combined_metric' available.\")\n",
    "    \n",
    "    # Row 3: Histograms for weighted_rmsd and fraction_outliers\n",
    "    with wrmsd_frac_out:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        # weighted_rmsd\n",
    "        if any(\"weighted_rmsd\" in r for r in filtered):\n",
    "            values = [r[\"weighted_rmsd\"] for r in filtered if \"weighted_rmsd\" in r]\n",
    "            axes[0].hist(values, bins=20)\n",
    "            axes[0].set_title(\"Histogram of weighted_rmsd\")\n",
    "            axes[0].set_xlabel(\"weighted_rmsd\")\n",
    "            axes[0].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        # fraction_outliers\n",
    "        if any(\"fraction_outliers\" in r for r in filtered):\n",
    "            values = [r[\"fraction_outliers\"] for r in filtered if \"fraction_outliers\" in r]\n",
    "            axes[1].hist(values, bins=20)\n",
    "            axes[1].set_title(\"Histogram of fraction_outliers\")\n",
    "            axes[1].set_xlabel(\"fraction_outliers\")\n",
    "            axes[1].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Row 4: Histograms for length_deviation and angle_deviation\n",
    "    with length_angle_out:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        # length_deviation\n",
    "        if any(\"length_deviation\" in r for r in filtered):\n",
    "            values = [r[\"length_deviation\"] for r in filtered if \"length_deviation\" in r]\n",
    "            axes[0].hist(values, bins=20)\n",
    "            axes[0].set_title(\"Histogram of length_deviation\")\n",
    "            axes[0].set_xlabel(\"length_deviation\")\n",
    "            axes[0].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        # angle_deviation\n",
    "        if any(\"angle_deviation\" in r for r in filtered):\n",
    "            values = [r[\"angle_deviation\"] for r in filtered if \"angle_deviation\" in r]\n",
    "            axes[1].hist(values, bins=20)\n",
    "            axes[1].set_title(\"Histogram of angle_deviation\")\n",
    "            axes[1].set_xlabel(\"angle_deviation\")\n",
    "            axes[1].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Row 5: Histograms for peak_ratio and percentage_unindexed\n",
    "    with peak_unindexed_out:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "        # peak_ratio\n",
    "        if any(\"peak_ratio\" in r for r in filtered):\n",
    "            values = [r[\"peak_ratio\"] for r in filtered if \"peak_ratio\" in r]\n",
    "            axes[0].hist(values, bins=20)\n",
    "            axes[0].set_title(\"Histogram of peak_ratio\")\n",
    "            axes[0].set_xlabel(\"peak_ratio\")\n",
    "            axes[0].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[0].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        # percentage_unindexed\n",
    "        if any(\"percentage_unindexed\" in r for r in filtered):\n",
    "            values = [r[\"percentage_unindexed\"] for r in filtered if \"percentage_unindexed\" in r]\n",
    "            axes[1].hist(values, bins=20)\n",
    "            axes[1].set_title(\"Histogram of percentage_unindexed\")\n",
    "            axes[1].set_xlabel(\"percentage_unindexed\")\n",
    "            axes[1].set_ylabel(\"Count\")\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, \"No data\", horizontalalignment='center', verticalalignment='center')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "filter_button.on_click(on_filter_clicked)\n",
    "\n",
    "#################################\n",
    "# 11) Button & function to convert filtered CSV to a stream file\n",
    "#################################\n",
    "convert_button = widgets.Button(description=\"Convert CSV to Stream\")\n",
    "\n",
    "def on_convert_clicked(_):\n",
    "    csv_to_stream_out.clear_output()\n",
    "    # Calculate output stream path based on FILTERED_CSV_PATH\n",
    "    OUTPUT_STREAM_PATH = os.path.join(os.path.dirname(FILTERED_CSV_PATH), 'filtered_metrics.stream')\n",
    "    csv_to_stream.write_stream_from_filtered_csv(\n",
    "        filtered_csv_path=FILTERED_CSV_PATH,\n",
    "        output_stream_path=OUTPUT_STREAM_PATH,\n",
    "        event_col=\"event_number\",    # adjust if needed\n",
    "        streamfile_col=\"stream_file\"   # adjust if needed\n",
    "    )\n",
    "    with csv_to_stream_out:\n",
    "        print(f\"CSV has been successfully converted to:\\n {OUTPUT_STREAM_PATH}.\")\n",
    "        \n",
    "convert_button.on_click(on_convert_clicked)\n",
    "\n",
    "#################################\n",
    "# 12) Layout: Arrange widgets and outputs into rows\n",
    "#################################\n",
    "# Control panel for all interactive widgets\n",
    "control_panel = widgets.VBox(\n",
    "    list(weight_text_fields.values()) +\n",
    "    [create_combined_button, combined_metric_slider] +\n",
    "    list(metric_sliders.values()) +\n",
    "    [filter_button]\n",
    ")\n",
    "\n",
    "# Row 1: Control panel (left) and combined metric histogram (right)\n",
    "row1 = widgets.HBox([control_panel, combined_out])\n",
    "\n",
    "# Row 2: CSV path message output\n",
    "row2 = csv_path_out\n",
    "\n",
    "# Row 3: Convert CSV to stream button and its output\n",
    "row3 = widgets.HBox([convert_button, csv_to_stream_out])\n",
    "\n",
    "# Row 4: Histograms for weighted_rmsd and fraction_outliers\n",
    "row4 = wrmsd_frac_out\n",
    "\n",
    "# Row 5: Histograms for length_deviation and angle_deviation\n",
    "row5 = length_angle_out\n",
    "\n",
    "# Row 6: Histograms for peak_ratio and percentage_unindexed\n",
    "row6 = peak_unindexed_out\n",
    "\n",
    "\n",
    "# Display everything as a vertical stack of rows\n",
    "display(widgets.VBox([row1, row2, row3, row4, row5, row6]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================================\n",
    "# Interactive Merging, SHELX Conversion, and MTZ Conversion\n",
    "# =============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da01b180c63464eab3b4e07fecd00dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='<h3>Merging Parameters</h3>'), FileChooser(path='/Users/xiaodong/Des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell to start the interactive Merging and Conversion tool\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Import file chooser widget\n",
    "try:\n",
    "    from ipyfilechooser import FileChooser\n",
    "except ImportError:\n",
    "    print(\"ipyfilechooser is required. Please install it with: pip install ipyfilechooser\")\n",
    "\n",
    "from merge import merge\n",
    "from convert_hkl_crystfel_to_shelx import convert_hkl_crystfel_to_shelx \n",
    "from convert_hkl_to_mtz import convert_hkl_to_mtz\n",
    "\n",
    "# Global variable to store merged output directory\n",
    "global_output_dir = None\n",
    "\n",
    "#################################\n",
    "# Merging Section\n",
    "#################################\n",
    "# File chooser for selecting the stream file\n",
    "stream_file_chooser = FileChooser(os.getcwd())\n",
    "stream_file_chooser.title = 'Select Stream File'\n",
    "stream_file_chooser.filter_pattern = '*.stream'  # Only show .stream files\n",
    "\n",
    "# Other merge parameters\n",
    "pointgroup_widget = widgets.Text(\n",
    "    value=\"\", \n",
    "    description=\"Pointgroup:\", \n",
    "    style={\"description_width\": \"150px\"}\n",
    ")\n",
    "num_threads_widget = widgets.IntText(\n",
    "    value=24, \n",
    "    description=\"Num Threads:\", \n",
    "    style={\"description_width\": \"150px\"}\n",
    ")\n",
    "iterations_widget = widgets.IntText(\n",
    "    value=5, \n",
    "    description=\"Iterations:\", \n",
    "    style={\"description_width\": \"150px\"}\n",
    ")\n",
    "merge_button = widgets.Button(description=\"Merge\")\n",
    "merge_output = widgets.Output()\n",
    "\n",
    "def on_merge_clicked(b):\n",
    "    global global_output_dir\n",
    "    merge_output.clear_output()\n",
    "    with merge_output:\n",
    "        stream_file = stream_file_chooser.selected\n",
    "        pointgroup = pointgroup_widget.value\n",
    "        num_threads = num_threads_widget.value\n",
    "        iterations = iterations_widget.value\n",
    "        \n",
    "        if not stream_file:\n",
    "            print(\"Please select a stream file first.\")\n",
    "            return\n",
    "        \n",
    "        print(\"Merging in progress...\")\n",
    "        output_dir = merge(\n",
    "            stream_file,\n",
    "            pointgroup=pointgroup,\n",
    "            num_threads=num_threads,\n",
    "            iterations=iterations,\n",
    "        )\n",
    "        if output_dir is not None:\n",
    "            print(\"Merging done. Results are in:\", output_dir)\n",
    "            global_output_dir = output_dir\n",
    "        else:\n",
    "            print(\"Merging failed. Please check the parameters and try again.\")\n",
    "\n",
    "merge_button.on_click(on_merge_clicked)\n",
    "\n",
    "merge_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Merging Parameters</h3>\"),\n",
    "    stream_file_chooser,\n",
    "    pointgroup_widget,\n",
    "    num_threads_widget,\n",
    "    iterations_widget,\n",
    "    merge_button,\n",
    "    merge_output\n",
    "])\n",
    "\n",
    "#################################\n",
    "# SHELX Conversion Section\n",
    "#################################\n",
    "shelx_button = widgets.Button(description=\"Convert to SHELX\")\n",
    "shelx_output = widgets.Output()\n",
    "\n",
    "def on_shelx_clicked(b):\n",
    "    shelx_output.clear_output()\n",
    "    with shelx_output:\n",
    "        if global_output_dir is None:\n",
    "            print(\"No merged output available. Please run merge first.\")\n",
    "        else:\n",
    "            print(\"Converting to SHELX...\")\n",
    "            convert_hkl_crystfel_to_shelx(global_output_dir)\n",
    "            print(\"Conversion to SHELX completed.\")\n",
    "\n",
    "shelx_button.on_click(on_shelx_clicked)\n",
    "\n",
    "shelx_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>SHELX Conversion</h3>\"),\n",
    "    shelx_button,\n",
    "    shelx_output\n",
    "])\n",
    "\n",
    "#################################\n",
    "# MTZ Conversion Section\n",
    "#################################\n",
    "# File chooser for selecting the cell file\n",
    "cell_file_chooser = FileChooser(os.getcwd())\n",
    "cell_file_chooser.title = 'Select Cell File'\n",
    "# Optionally set filter_pattern if your cell file has a specific extension\n",
    "\n",
    "mtz_button = widgets.Button(description=\"Convert to MTZ\")\n",
    "mtz_output = widgets.Output()\n",
    "\n",
    "def on_mtz_clicked(b):\n",
    "    mtz_output.clear_output()\n",
    "    with mtz_output:\n",
    "        if global_output_dir is None:\n",
    "            print(\"No merged output available. Please run merge first.\")\n",
    "        else:\n",
    "            cellfile_path = cell_file_chooser.selected\n",
    "            if not cellfile_path:\n",
    "                print(\"Please select a cell file first.\")\n",
    "                return\n",
    "            print(\"Converting to MTZ...\")\n",
    "            convert_hkl_to_mtz(global_output_dir, cellfile_path=cellfile_path)\n",
    "            print(\"Conversion to MTZ completed.\")\n",
    "\n",
    "mtz_button.on_click(on_mtz_clicked)\n",
    "\n",
    "mtz_controls = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>MTZ Conversion</h3>\"),\n",
    "    cell_file_chooser,\n",
    "    mtz_button,\n",
    "    mtz_output\n",
    "])\n",
    "\n",
    "#################################\n",
    "# Display All Controls\n",
    "#################################\n",
    "display(widgets.VBox([\n",
    "    merge_controls,\n",
    "    shelx_controls,\n",
    "    mtz_controls\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Filtered Stream File Using Partialator (Non-Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merge import merge\n",
    "\n",
    "stream_file = \"/path/to/filtered_metrics.stream\"\n",
    "pointgroup = \"\"\n",
    "num_threads = 24\n",
    "iterations = 5\n",
    "\n",
    "output_dir = merge(\n",
    "    stream_file,\n",
    "    pointgroup=pointgroup,\n",
    "    num_threads=num_threads,\n",
    "    iterations=iterations,\n",
    ")\n",
    "\n",
    "if output_dir is not None:\n",
    "    print(\"Merging done. Results are in:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to SHELX Compatible .hkl (Non-Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_hkl_crystfel_to_shelx import convert_hkl_crystfel_to_shelx \n",
    "# output_dir = \"\" # If defined above comment out this line\n",
    "convert_hkl_crystfel_to_shelx(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to mtz (Non-Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_hkl_to_mtz import convert_hkl_to_mtz\n",
    "# output_dir = \"\" # If defined above comment out this line\n",
    "# cellfile_path = \"\"  # If defined above comment out this line\n",
    "convert_hkl_to_mtz(output_dir, cellfile_path=cellfile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyxem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
