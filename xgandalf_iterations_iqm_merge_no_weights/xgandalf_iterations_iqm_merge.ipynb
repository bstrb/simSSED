{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the CrystFEL-based processing\n",
    "\n",
    "This notebook comprises a workflow using CrystFEL-based tools combined with original scripts. Below is a step-by-step guide:\n",
    "\n",
    "1. **Run Indexamajig** (`gandalf_iterator`)  \n",
    "   - Perform peakfinding, indexing, and integration for each HDF5 file in the specified folder, varying beam center coordinates on a grid withing a given radius.\n",
    "\n",
    "2. **Evaluate IQM** (`automate_evaluation`)  \n",
    "   - Parse stream files for indexing quality metrics (IQMs), apply weights, and identify the best results.\n",
    "\n",
    "3. **Merge** (`merge`)  \n",
    "   - Merge the best result stream file to refine cell parameters and symmetry.\n",
    "\n",
    "4. **Convert**  \n",
    "   - **to `.hkl`** for ShelX (`convert_hkl_crystfel_to_shelx`).  \n",
    "   - **to `.mtz`** for downstream crystallographic tools (`convert_hkl_to_mtz`).\n",
    "\n",
    "Please ensure that preprocessing (peak finding, center finding and center refinement) has been done and that you have the required packages and environment set up (CrystFEL, Python packages, etc.) before proceeding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Indexamajig with options for peakfinding, indexing and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gandalf_radial_iterator import gandalf_iterator\n",
    "\n",
    "geomfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTAsim.geom\"       # .geom file\n",
    "cellfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTA.cell\"          # .cell file\n",
    "\n",
    "input_path =   \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24\"      # .h5 folder will also be output folder\n",
    "\n",
    "output_file_base = \"LTA\"    # output files will be named output_file_base_xcoord_ycoord.h5\n",
    "\n",
    "num_threads = 8             # number of CPU threads to use\n",
    "x, y = 512.5, 512.5         # initial beam center from where iterations will start\n",
    "\n",
    "\"\"\"Define the grid and maximum radius for iterations.\n",
    "As example max_radius = 1, step = 0.2 will give 81 iterations.\n",
    "Iterations will start at the center and move radially outwards.\n",
    "\"\"\"\n",
    "max_radius = 1              # maximum radius in pixels\n",
    "step = 0.2                  # grid granularity in pixels\n",
    "\n",
    "extra_flags=[\n",
    "# PEAKFINDING\n",
    "\"--no-revalidate\",\n",
    "\"--no-half-pixel-shift\",\n",
    "\"--peaks=cxi\", \n",
    "\"--min-peaks=15\",\n",
    "# INDEXING\n",
    "\"--indexing=xgandalf\",\n",
    "\"--tolerance=10,10,10,5\",\n",
    "\"--no-refine\",\n",
    "\"--xgandalf-sampling-pitch=5\",\n",
    "\"--xgandalf-grad-desc-iterations=1\",\n",
    "\"--xgandalf-tolerance=0.02\",\n",
    "# INTEGRATION\n",
    "\"--integration=rings\",\n",
    "\"--int-radius=4,5,9\",\n",
    "\"--fix-profile-radius=70000000\",\n",
    "# OUTPUT\n",
    "\"--no-non-hits-in-stream\",\n",
    "]\n",
    "\n",
    "\"\"\"Examples of extra flags(see crystfel documentation https://www.desy.de/~twhite/crystfel/manual-indexamajig.html):\"\"\"\n",
    "\n",
    "\"\"\" Basic options\n",
    "\"--highres=n\",\n",
    "\"--no-image-data\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Peakfinding\n",
    "\"--peaks=cxi\",\n",
    "\"--peak-radius=inner,middle,outer\",\n",
    "\"--min-peaks=n\",\n",
    "\"--median-filter=n\",\n",
    "\"--filter-noise\",\n",
    "\"--no-revalidate\",\n",
    "\"--no-half-pixel-shift\",\n",
    "\n",
    "\"--peaks=peakfinder9\",\n",
    "\"--min-snr=1\",\n",
    "\"--min-snr-peak-pix=6\",\n",
    "\"--min-snr-biggest-pix=1\",\n",
    "\"--min-sig=9\",\n",
    "\"--min-peak-over-neighbour=5\",\n",
    "\"--local-bg-radius=5\",\n",
    "\n",
    "\"--peaks=peakfinder8\",\n",
    "\"--threshold=45\",\n",
    "\"--min-snr=3\",\n",
    "\"--min-pix-count=3\",\n",
    "\"--max-pix-count=500\",\n",
    "\"--local-bg-radius=9\",\n",
    "\"--min-res=30\",\n",
    "\"--max-res=500\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Indexing\n",
    "\"--indexing=xgandalf\",\n",
    "\n",
    "\"--tolerance=tol\"\n",
    "\"--no-check-cell\",\n",
    "\"--no-check-peaks\",\n",
    "\"--multi\",\n",
    "\"--no-retry\",\n",
    "\"--no-refine\",\n",
    "\n",
    "\"--xgandalf-sampling-pitch=n\"\n",
    "\"--xgandalf-grad-desc-iterations=n\"\n",
    "\"--xgandalf-tolerance=n\"\n",
    "\"--xgandalf-no-deviation-from-provided-cell\"\n",
    "\"--xgandalf-max-lattice-vector-length=n\"\n",
    "\"--xgandalf-min-lattice-vector-length=n\"\n",
    "\"--xgandalf-max-peaks=n\"\n",
    "\"--xgandalf-fast-execution\"\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Integration\n",
    "\"--fix-profile-radius=n\",\n",
    "\"--fix-divergence=n\",\n",
    "\"--integration=rings\",\n",
    "\"--int-radius=4,5,10\",\n",
    "\"--push-res=n\",\n",
    "\"--overpredict\",\n",
    "\"--cell-parameters-only\",\n",
    "\"\"\"\n",
    "\n",
    "\"\"\" Output\n",
    "\"--no-non-hits-in-stream\",\n",
    "\"--no-peaks-in-stream\",\n",
    "\"--no-refls-in-stream\",\n",
    "\"--serial-offset\n",
    "\"\"\"\n",
    "\n",
    "gandalf_iterator(x, y, geomfile_path, cellfile_path, input_path, output_file_base, num_threads, max_radius=max_radius, step=step, extra_flags=extra_flags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the IQM with chosen weights for all frames across all index results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automate_evaluation import automate_evaluation\n",
    "\n",
    "# Enter folder with stream file results from indexamajig. \n",
    "# Note that ALL stream files in the folder will be processed.\n",
    "\n",
    "stream_file_folder = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2\" \n",
    "\n",
    "\"\"\"\n",
    "The following metrics will be evaluated for analysis in the next step:\n",
    "\n",
    "- 'weighted_rmsd'\n",
    "- 'fraction_outliers'\n",
    "- 'length_deviation'\n",
    "- 'angle_deviation'\n",
    "- 'peak_ratio'\n",
    "- 'percentage_indexed'\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "automate_evaluation(stream_file_folder, wrmsd_tolerance=2, indexing_tolerance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from interactive_iqm_v2 import (\n",
    "    read_metric_csv,\n",
    "    select_best_results_by_event,\n",
    "    get_metric_ranges,\n",
    "    create_combined_metric,\n",
    "    filter_rows,\n",
    "    write_filtered_csv\n",
    ")\n",
    "\n",
    "#################################\n",
    "# 1) PATHS\n",
    "#################################\n",
    "CSV_PATH = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/normalized_metrics.csv\"\n",
    "FILTERED_CSV_PATH = os.path.join(os.path.dirname(CSV_PATH), 'filtered_metrics.csv')\n",
    "\n",
    "#################################\n",
    "# 2) Read the CSV (group by event)\n",
    "#################################\n",
    "grouped_data = read_metric_csv(CSV_PATH, group_by_event=True)\n",
    "\n",
    "#################################\n",
    "# 3) If you have multiple rows per event, pick \"best\" row\n",
    "#################################\n",
    "best_rows = select_best_results_by_event(grouped_data, sort_metric='weighted_rmsd')\n",
    "\n",
    "#################################\n",
    "# 4) Metrics in your CSV\n",
    "#################################\n",
    "metrics_in_order = [\n",
    "    'weighted_rmsd',\n",
    "    'fraction_outliers',\n",
    "    'length_deviation',\n",
    "    'angle_deviation',\n",
    "    'peak_ratio',\n",
    "    'percentage_unindexed'\n",
    "]\n",
    "\n",
    "#################################\n",
    "# 5) Helper: plot separate histograms per metric\n",
    "#################################\n",
    "def make_histograms(rows, metrics=None, bins=20):\n",
    "    if not rows:\n",
    "        print(\"No data to plot histograms for.\")\n",
    "        return\n",
    "    if metrics is None:\n",
    "        metrics = metrics_in_order\n",
    "    for m in metrics:\n",
    "        if any(m in r for r in rows):  # ensure row has that key\n",
    "            values = [r[m] for r in rows if m in r]\n",
    "            plt.figure()\n",
    "            plt.hist(values, bins=bins)\n",
    "            plt.title(f\"Histogram of {m}\")\n",
    "            plt.xlabel(m)\n",
    "            plt.ylabel(\"Count\")\n",
    "            plt.show()\n",
    "\n",
    "#################################\n",
    "# 6) Create threshold sliders for each original metric\n",
    "#    so user can filter by \"metric <= slider_value\"\n",
    "#################################\n",
    "ranges_dict = get_metric_ranges(best_rows, metrics=metrics_in_order)\n",
    "metric_sliders = {}\n",
    "\n",
    "def create_slider(metric_name, min_val, max_val):\n",
    "    # We'll do a ≤ filter, so default slider to max => \"include all\"\n",
    "    default_val = max_val\n",
    "    step = (max_val - min_val) / 100.0 if max_val != min_val else 0.01\n",
    "    \n",
    "    slider = widgets.FloatSlider(\n",
    "        value=default_val,\n",
    "        min=min_val,\n",
    "        max=max_val,\n",
    "        step=step,\n",
    "        description=f\"{metric_name} ≤\"\n",
    "    )\n",
    "    return slider\n",
    "\n",
    "for metric in metrics_in_order:\n",
    "    mn, mx = ranges_dict[metric]\n",
    "    metric_sliders[metric] = create_slider(metric, mn, mx)\n",
    "\n",
    "#################################\n",
    "# 7) Text fields for per-metric weights to create a combined metric\n",
    "#################################\n",
    "weight_text_fields = {}\n",
    "for metric in metrics_in_order:\n",
    "    weight_text_fields[metric] = widgets.FloatText(\n",
    "        value=0.0,  # default to 0 => skip that metric in combined sum\n",
    "        description=f\"Weight for {metric}\",\n",
    "        style={\"description_width\": \"initial\"} \n",
    "    )\n",
    "\n",
    "#################################\n",
    "# 8) A slider to threshold the combined metric\n",
    "#################################\n",
    "combined_metric_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.01,\n",
    "    description=\"combined_metric ≤\"\n",
    ")\n",
    "\n",
    "#################################\n",
    "# 9) Button & function to create/update combined metric\n",
    "#################################\n",
    "def create_or_update_combined_metric(_):\n",
    "    \"\"\"\n",
    "    Read user-entered weights for each metric, compute 'combined_metric' \n",
    "    for best_rows, and update the combined_metric_slider's min/max/value.\n",
    "    \"\"\"\n",
    "    # Gather weights from the text fields\n",
    "    selected_metrics = []\n",
    "    weights_list = []\n",
    "    for m in metrics_in_order:\n",
    "        w = weight_text_fields[m].value\n",
    "        selected_metrics.append(m)\n",
    "        weights_list.append(w)\n",
    "\n",
    "    # Compute the combined metric\n",
    "    create_combined_metric(\n",
    "        rows=best_rows,\n",
    "        metrics_to_combine=selected_metrics,\n",
    "        weights=weights_list,\n",
    "        new_metric_name=\"combined_metric\"\n",
    "    )\n",
    "\n",
    "    # Compute new min/max for the combined metric\n",
    "    combined_vals = [r[\"combined_metric\"] for r in best_rows]\n",
    "    cmin, cmax = min(combined_vals), max(combined_vals)\n",
    "\n",
    "    # Safely update the slider so no out-of-range errors\n",
    "    with combined_metric_slider.hold_trait_notifications():\n",
    "        current_val = combined_metric_slider.value\n",
    "        if current_val < cmin or current_val > cmax:\n",
    "            current_val = cmax  # or cmin, as you prefer\n",
    "\n",
    "        combined_metric_slider.min = cmin\n",
    "        combined_metric_slider.max = cmax\n",
    "        combined_metric_slider.value = current_val\n",
    "\n",
    "    print(\"Created/updated 'combined_metric' using user-entered weights.\")\n",
    "\n",
    "create_combined_button = widgets.Button(description=\"Create Combined Metric\")\n",
    "create_combined_button.on_click(create_or_update_combined_metric)\n",
    "\n",
    "#################################\n",
    "# 10) Button to apply thresholds, show histograms, and write CSV\n",
    "#################################\n",
    "filter_button = widgets.Button(description=\"Apply Thresholds & Show Histograms\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_filter_clicked(_):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "\n",
    "        # Build thresholds from slider values on the original metrics\n",
    "        thresholds = {m: metric_sliders[m].value for m in metrics_in_order}\n",
    "        \n",
    "        # If 'combined_metric' exists, also threshold it\n",
    "        if \"combined_metric\" in best_rows[0]:\n",
    "            thresholds[\"combined_metric\"] = combined_metric_slider.value\n",
    "\n",
    "        # Filter the best_rows\n",
    "        filtered = filter_rows(best_rows, thresholds)\n",
    "\n",
    "        print(f\"Filtering... {len(best_rows)} rows -> {len(filtered)} pass thresholds.\\n\")\n",
    "        \n",
    "        if filtered:\n",
    "            # Show histograms for whichever metrics we used\n",
    "            make_histograms(filtered, metrics=list(thresholds.keys()))\n",
    "        else:\n",
    "            print(\"No rows passed the thresholds, skipping histograms.\")\n",
    "\n",
    "        # Write a CSV of the filtered rows (including the combined metric, if present)\n",
    "        if filtered:\n",
    "            write_filtered_csv(filtered, FILTERED_CSV_PATH)\n",
    "            print(f\"Filtered CSV (including 'combined_metric' if created) written to:\\n  {FILTERED_CSV_PATH}\")\n",
    "\n",
    "filter_button.on_click(on_filter_clicked)\n",
    "\n",
    "#################################\n",
    "# 11) Display everything\n",
    "#################################\n",
    "# We'll show:\n",
    "#   - text fields for weights\n",
    "#   - \"Create Combined Metric\" button\n",
    "#   - combined_metric threshold slider\n",
    "#   - per-metric threshold sliders\n",
    "#   - \"Apply Thresholds & Show Histograms\" button\n",
    "#   - output area\n",
    "all_widgets = (\n",
    "    list(weight_text_fields.values()) +\n",
    "    [create_combined_button, combined_metric_slider] +\n",
    "    list(metric_sliders.values()) +\n",
    "    [filter_button, output_area]\n",
    ")\n",
    "display(*all_widgets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b025eb975bd04806b11a69a79a8a43be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Create Stream from CSV', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d27ff91a3ae4c9fa92185e307de53da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import csv_to_stream  # Your script name (csv_to_stream.py)\n",
    "import os\n",
    "\n",
    "# 1) Paths:\n",
    "FILTERED_CSV_PATH = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/filtered_metrics.csv\"\n",
    "OUTPUT_STREAM_PATH = os.path.join(os.path.dirname(FILTERED_CSV_PATH), 'filtered_metrics.stream')\n",
    "\n",
    "# 2) Button & output area\n",
    "create_stream_button = widgets.Button(description=\"Create Stream from CSV\")\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_create_stream_clicked(_):\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        # Call our function from csv_to_stream.py\n",
    "        csv_to_stream.write_stream_from_filtered_csv(\n",
    "            filtered_csv_path=FILTERED_CSV_PATH,\n",
    "            output_stream_path=OUTPUT_STREAM_PATH,\n",
    "            event_col=\"event_number\",    # or whatever column name your CSV uses\n",
    "            streamfile_col=\"stream_file\" # or the CSV column that points to the .stream path\n",
    "        )\n",
    "\n",
    "create_stream_button.on_click(on_create_stream_clicked)\n",
    "\n",
    "# 3) Display the button and output\n",
    "display(create_stream_button, output_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the best results stream file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running partialator for stream file: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/filtered_metrics copy 2.stream\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partialator Progress: 100%|██████████| 7/7 [00:01<00:00,  6.80Residual/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partialator completed for stream file: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/filtered_metrics copy 2.stream\n",
      "Merging done. Results are in: /Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/filtered_metrics copy 2_merge_5_iter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from merge import merge\n",
    "\n",
    "stream_file = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/filtered_metrics copy 2.stream\"\n",
    "pointgroup = \"m-3m\"\n",
    "num_threads = 24\n",
    "iterations = 5\n",
    "\n",
    "output_dir = merge(\n",
    "    stream_file,\n",
    "    pointgroup=pointgroup,\n",
    "    num_threads=num_threads,\n",
    "    iterations=iterations,\n",
    ")\n",
    "\n",
    "if output_dir is not None:\n",
    "    print(\"Merging done. Results are in:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to shelx compatible .hkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_hkl_crystfel_to_shelx import convert_hkl_crystfel_to_shelx \n",
    "output_dir = \"/Users/xiaodong/Desktop/simulations/LTA/simulation-24/xgandalf_iterations_max_radius_1_step_0.2/merged_IQM_1_1_1_1_1_1_merge_5_iter\"\n",
    "convert_hkl_crystfel_to_shelx(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to mtz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from convert_hkl_to_mtz import convert_hkl_to_mtz\n",
    "cellfile_path = \"/Users/xiaodong/Desktop/simulations/LTA/LTA.cell\"  # If defined above comment out this line\n",
    "convert_hkl_to_mtz(output_dir, cellfile_path=cellfile_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyxem-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
